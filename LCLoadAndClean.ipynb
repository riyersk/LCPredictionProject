{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to read in the data from csv files.  A lending club investor was kind enough to help me get this data from lending club, and the list below comprises the file names that I chose to give the csv files. We're trying to predict whether or not the loan will be charged off, so we delete the fields that would reveal, after the fact, that the loan has been charged off. We also delete any columns that are null across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,49,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,19,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,19,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,118) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Loading\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "fnames = ['LC1213.csv','LC14.csv','LC15.csv','LC16Q1.csv','LC16Q2.csv','LC16Q3.csv','LC16Q4.csv','LC17Q1.csv','LC17Q2.csv','LC17Q3.csv']\n",
    "for i in fnames:\n",
    "    dfs.append(pd.read_csv(i))\n",
    "print('Done with Loading')\n",
    "for i in dfs:\n",
    "    del i['id']\n",
    "    del i['url']\n",
    "    del i['recoveries']\n",
    "    del i['collection_recovery_fee']\n",
    "    del i['debt_settlement_flag']\n",
    "    del i['debt_settlement_flag_date']\n",
    "    del i['settlement_status']\n",
    "    del i['settlement_date']\n",
    "    del i['settlement_amount']\n",
    "    del i['settlement_percentage']\n",
    "    del i['settlement_term']\n",
    "    for st in i.columns.values:\n",
    "        if len(i[np.invert(i[st].isnull())])==0 and len(i[i[st].isnull()])==len(i):\n",
    "            del i[st]\n",
    "        else:\n",
    "            a = i.dropna(subset = [st])\n",
    "            if(len(a[st].unique())==1):\n",
    "                del i[st]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we keep features that are common across all of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [x for x in dfs[1].columns.values if x in dfs[0].columns.values]\n",
    "for i in range(2,len(dfs)):\n",
    "    feat = [x for x in dfs[i].columns.values if x in feat]\n",
    "for i in dfs:\n",
    "    for j in i.columns.values:\n",
    "        if j not in feat:\n",
    "            del i[j]\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to keep the loans that have either been fully paid or charged off. If a loan is still active, it's not helpful to train or test our model, since we don't know whether that loan will be fully paid or charged off.  Let's also take this opportunity to once again delete any features that consist entirely of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.loan_status.isin(['Fully Paid', 'Charged Off'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for st in df.columns.values:\n",
    "    if len(df[np.invert(df[st].isnull())])==0 and len(df[df[st].isnull()])==len(df):\n",
    "        del df[st]\n",
    "    else:\n",
    "        a = df.dropna(subset = [st])\n",
    "        if(len(a[st].unique())==1):\n",
    "            del df[st]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll get some features in the format we want and delete all features we couldn't find on Lending Club's investor interface.  The idea is to only use features a casual investor would be able to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['int_rate'] = [float(x.split('%')[0]) for x in df['int_rate']]\n",
    "dels = ['hardship_reason', 'hardship_status','hardship_amount','hardship_start_date','hardship_end_date','payment_plan_start_date'\\\n",
    "                ,'hardship_dpd', 'hardship_loan_status','orig_projected_additional_accrued_interest'\\\n",
    "                ,'hardship_payoff_balance_amount','hardship_last_payment_amount']\n",
    "for i in dels:\n",
    "    df = df[pd.isnull(df[i])]\n",
    "    del df[i]\n",
    "df = df[df.loan_amnt == df.funded_amnt]\n",
    "del df['funded_amnt']\n",
    "del df['funded_amnt_inv']\n",
    "del df['grade']\n",
    "del df['title']\n",
    "del df['addr_state']\n",
    "del df['initial_list_status']\n",
    "del df['total_pymnt_inv']\n",
    "del df['last_credit_pull_d']\n",
    "del df['tot_coll_amt']\n",
    "del df['total_rev_hi_lim']\n",
    "del df['acc_open_past_24mths']\n",
    "del df['avg_cur_bal']\n",
    "del df['bc_open_to_buy']\n",
    "del df['bc_util']\n",
    "del df['chargeoff_within_12_mths']\n",
    "del df['mo_sin_old_il_acct']\n",
    "del df['mo_sin_old_rev_tl_op']\n",
    "del df['mo_sin_rcnt_rev_tl_op']\n",
    "del df['mo_sin_rcnt_tl']\n",
    "del df['mort_acc']\n",
    "del df['mths_since_recent_bc']\n",
    "del df['mths_since_recent_bc_dlq']\n",
    "del df['mths_since_recent_inq']\n",
    "del df['num_actv_bc_tl']\n",
    "del df['num_actv_rev_tl']\n",
    "del df['mths_since_recent_revol_delinq']\n",
    "del df['num_accts_ever_120_pd']\n",
    "del df['num_rev_tl_bal_gt_0']\n",
    "del df['num_sats']\n",
    "del df['num_tl_30dpd']\n",
    "del df['num_tl_120dpd_2m']\n",
    "del df['num_tl_90g_dpd_24m']\n",
    "del df['num_bc_tl']\n",
    "del df['num_il_tl']\n",
    "del df['num_op_rev_tl']\n",
    "del df['num_rev_accts']\n",
    "del df['num_bc_sats']\n",
    "del df['total_pymnt']\n",
    "del df['total_rec_prncp']\n",
    "del df['total_rec_int']\n",
    "del df['total_rec_late_fee']\n",
    "del df['last_pymnt_d']\n",
    "del df['last_pymnt_amnt']\n",
    "del df['last_fico_range_high']\n",
    "del df['last_fico_range_low']\n",
    "del df['tot_cur_bal']\n",
    "del df['num_tl_op_past_12m']\n",
    "del df['pct_tl_nvr_dlq']\n",
    "del df['percent_bc_gt_75']\n",
    "del df['pub_rec_bankruptcies']\n",
    "del df['tax_liens']\n",
    "del df['tot_hi_cred_lim']\n",
    "del df['total_bal_ex_mort']\n",
    "del df['total_bc_limit']\n",
    "del df['total_il_high_credit_limit']\n",
    "del df['emp_title']\n",
    "del df['zip_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtifill(x,y):\n",
    "    if(pd.isnull(x) and y==0.0):\n",
    "        return 10000000000000.0\n",
    "    else:\n",
    "        return x\n",
    "df['dti'] = [dtifill(x,y) for x,y in zip(df['dti'],df['annual_inc'])]\n",
    "def dtifill2(x):\n",
    "    if pd.isnull(x):\n",
    "        return 10000000000000.0\n",
    "    else:\n",
    "        return x\n",
    "df['dti'] = [dtifill2(x) for x in df['dti']]\n",
    "def mfill(x):\n",
    "    if pd.isnull(x):\n",
    "        return 100000.0\n",
    "    else:\n",
    "        return x\n",
    "df['mths_since_last_delinq'] = [mfill(x) for x in df['mths_since_last_delinq']]\n",
    "df['mths_since_last_record'] = [mfill(x) for x in df['mths_since_last_record']]\n",
    "df['mths_since_last_major_derog'] = [mfill(x) for x in df['mths_since_last_major_derog']]\n",
    "def utilify(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    else:\n",
    "        return float(x.split('%')[0])\n",
    "df['revol_util'] = [utilify(x) for x in df['revol_util']]\n",
    "def revutilify(x):\n",
    "    if(pd.isnull(x)):\n",
    "        return 1000000.0\n",
    "    else:\n",
    "        return x\n",
    "df['revol_util'] = [revutilify(x) for x in df['revol_util']]\n",
    "def termify(x):\n",
    "    return int(x.split(' ')[1])\n",
    "df['term'] = [termify(x) for x in df['term']]\n",
    "empify = {'10+ years':10.1,'4 years':4.0,'2 years':2.0,'5 years':5.0,'7 years':7.0,'3 years':3.0,\\\n",
    "         '6 years':6.0,'1 year':1.0,'9 years':9.0,'8 years':8.0,'< 1 year':0.5, 'n/a':0.0}\n",
    "df['emp_length'] = [empify[x] for x in df['emp_length']]\n",
    "m2i = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "def d2i(x):\n",
    "    y = x.split('-')\n",
    "    return m2i[y[0]]+12*(int(y[1])-2012)\n",
    "df['issue_d'] = [d2i(x) for x in df['issue_d']]\n",
    "m2i2 = {'Jan':12,'Feb':11,'Mar':10,'Apr':9,'May':8,'Jun':7,'Jul':6,'Aug':5,'Sep':4,'Oct':3,'Nov':2,'Dec':1}\n",
    "def e2i(x):\n",
    "    z = x.split('-')\n",
    "    return m2i2[z[0]] + 12*(2011-int(z[1]))\n",
    "df['earliest_cr_line'] = [e2i(x) for x in df['earliest_cr_line']]\n",
    "df['earliest_cr_line'] = [x+y for x,y in zip(df['earliest_cr_line'], df['issue_d'])]\n",
    "def lstat(x):\n",
    "    if(x=='Fully Paid'):\n",
    "        return 0\n",
    "    elif(x=='Charged Off'):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "df['loan_status'] = [lstat(x) for x in df['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.dropna(inplace=True)\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LCDC3.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our monkey test! We'll simply shove our data into 3 models and see what the results are like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varss = []\n",
    "for i in df.columns.values:\n",
    "    if i != 'loan_status':\n",
    "        varss.append(i)\n",
    "y = df['loan_status']\n",
    "X = df[varss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ret(y_pred, y_test, X_test):\n",
    "    portfolio = []\n",
    "    rates = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]==0:\n",
    "            portfolio.append(y_test[i])\n",
    "            rates.append(X_test[i])\n",
    "    if len(portfolio)==0:\n",
    "        return float(-1)\n",
    "    return ((float(len(portfolio)-sum(portfolio))/float(len(portfolio)))*(1.+ (np.mean(rates)/100.))) - 1\n",
    "def myScore(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return ret(list(y_pred), list(y), list(X['int_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781693007187\n",
      "Precision: 0.443293779216\n",
      "Recall: 0.145363644939\n",
      "F1: 0.218934806159\n",
      "Rate of return: -0.087007910152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "monkey = BaggingClassifier()\n",
    "monkey.fit(X_train, y_train)\n",
    "y_pred = monkey.predict(X_test)\n",
    "print('Accuracy: ', end = '')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', end = '')\n",
    "print(metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', end = '')\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "print('F1: ', end = '')\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print('Rate of return: ', end = '')\n",
    "print(myScore(monkey, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790687169916\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "Rate of return: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/subramanianiyer/anaconda2/envs/mypython3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10234325529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "monkey4 = LogisticRegression()\n",
    "monkey4.fit(X_train, y_train)\n",
    "y_pred = monkey4.predict(X_test)\n",
    "print('Accuracy: ', end = '')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', end = '')\n",
    "print(metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', end = '')\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "print('F1: ', end = '')\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print('Rate of return: ', end = '')\n",
    "print(myScore(monkey4, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.785207282691\n",
      "Precision: 0.461125525633\n",
      "Recall: 0.121545137251\n",
      "F1: 0.192381627816\n",
      "Rate of return: -0.0894826525892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "monkey5 = RandomForestClassifier()\n",
    "monkey5.fit(X_train, y_train)\n",
    "y_pred = monkey5.predict(X_test)\n",
    "print('Accuracy: ', end = '')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', end = '')\n",
    "print(metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', end = '')\n",
    "print(metrics.recall_score(y_test, y_pred))\n",
    "print('F1: ', end = '')\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print('Rate of return: ', end = '')\n",
    "print(myScore(monkey5, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
